{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP2omt8j7y1CJtEOFoSPtXl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBOb6vqO2JzP","executionInfo":{"status":"ok","timestamp":1764138687425,"user_tz":420,"elapsed":6120,"user":{"displayName":"Sebastian Roman Lugo Chavez","userId":"10373905514091118663"}},"outputId":"59ac0bfb-1502-4816-cb37-2297248fcc23"},"outputs":[{"output_type":"stream","name":"stdout","text":["Numba CUDA available: True\n","CPU Time: 0.00 ms\n","GPU transfer to device: 244.90 ms\n","GPU kernel execution:   1741.80 ms\n","GPU transfer to host:   15.45 ms\n","Total GPU time:         2002.15 ms\n"]}],"source":["import numpy as np\n","import time\n","from numba import cuda, config\n","\n","config.CUDA_ENABLE_PYNVJITLINK = 0\n","\n","print(\"Numba CUDA available:\", cuda.is_available())\n","\n","@cuda.jit\n","def first_kernel(a, result):\n","    idx = cuda.grid(1)\n","    if idx < a.size:\n","        result[idx] = a[idx]\n","\n","def main():\n","    # 1. Initialize data on CPU\n","    N = 10_000_000\n","    a_cpu = np.arange(N, dtype=np.float32)\n","\n","    # ---------------- CPU ----------------\n","    start = time.time()\n","    result_cpu = a_cpu\n","    cpu_time = time.time() - start\n","    print(f\"CPU Time: {cpu_time * 1e3:.2f} ms\")\n","\n","    # ---------------- GPU ----------------\n","    start = time.time()\n","    a_gpu = cuda.to_device(a_cpu)\n","    result_gpu = cuda.device_array_like(a_cpu)\n","    transfer_in_time = time.time() - start\n","\n","    threads_per_block = 128\n","    blocks_per_grid = (N + threads_per_block - 1) // threads_per_block\n","\n","    start = time.time()\n","    first_kernel[blocks_per_grid, threads_per_block](a_gpu, result_gpu)\n","    cuda.synchronize()\n","    kernel_time = time.time() - start\n","\n","    start = time.time()\n","    result_from_gpu = result_gpu.copy_to_host()\n","    transfer_out_time = time.time() - start\n","\n","    print(f\"GPU transfer to device: {transfer_in_time * 1e3:.2f} ms\")\n","    print(f\"GPU kernel execution:   {kernel_time * 1e3:.2f} ms\")\n","    print(f\"GPU transfer to host:   {transfer_out_time * 1e3:.2f} ms\")\n","\n","    total_gpu_time_ms = (transfer_in_time + kernel_time + transfer_out_time) * 1e3\n","    print(f\"Total GPU time:         {total_gpu_time_ms:.2f} ms\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}